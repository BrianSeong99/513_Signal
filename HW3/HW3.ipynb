{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLRJNDGiPU37"
      },
      "source": [
        "## TECHIN 513 - Basic ML\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Install the required packages (scikit-learn, TensorFlow, Keras, PyTorch, and, pandas) if they are not already installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "JVHNfDPhPjyw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<SliceBackward0>)\n",
            "100 tensor([[ 841.],\n",
            "        [  53.],\n",
            "        [ 215.],\n",
            "        [ 587.],\n",
            "        [1145.],\n",
            "        [ 925.],\n",
            "        [ 915.],\n",
            "        [1021.],\n",
            "        [1425.],\n",
            "        [  77.]])\n",
            "Final Train Accuracy tensor(0) tensor(0.)\n"
          ]
        }
      ],
      "source": [
        "# use pip to install the packages\n",
        "# !pip install scikit-learn TensorFlow Keras PyTorch pandas numpy\n",
        "\n",
        "# Import necessary packages\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "\n",
        "# # Task 1: Load the Iris dataset\n",
        "# iris = datasets.load_iris()\n",
        "# X = iris.data\n",
        "# y = iris.target\n",
        "\n",
        "# # Task 2: Split the data into training and testing sets\n",
        "# # use train_test_split function to split the data with test_size = 0.2 and random_state = 42\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state=42)\n",
        "\n",
        "# # Task 3: Train a Random Forest Classifier on the training data\n",
        "# # import RandomForestClassifier from sklearn and fit it with training data\n",
        "# clf = RandomForestClassifier()\n",
        "# clf.fit(X_train, y_train)\n",
        "\n",
        "# # Task 4: Evaluate the classifier on the testing data\n",
        "# # use clf.score function to evaluate the classifier on the testing data\n",
        "# # print the accuracy of the classifier\n",
        "# score = clf.score(X_test, y_test)\n",
        "# print(score)\n",
        "\n",
        "# # Task 5: Load the MNIST dataset\n",
        "# # use keras.datasets.mnist.load_data() to load the dataset\n",
        "# (train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
        "# print(\"Train images shape:\", train_images.shape)\n",
        "# print(\"Train labels shape:\", train_labels.shape)\n",
        "# print(\"Test images shape: \", test_images.shape)\n",
        "# print(\"Test labels shape: \", test_labels.shape)\n",
        "\n",
        "# # Task 6: Preprocess the data\n",
        "# # normalize the data by dividing by 255.0\n",
        "# # use to_categorical from keras.utils to one-hot encode the labels\n",
        "# labels_train = keras.utils.to_categorical(train_labels)\n",
        "# labels_test = keras.utils.to_categorical(test_labels)\n",
        "# print(labels_train.shape)\n",
        "# print(labels_test.shape)\n",
        "# train_images = np.reshape(train_images, (-1, 784))\n",
        "# test_images = np.reshape(test_images, (-1, 784))\n",
        "# train_images = train_images.astype('float32') / 255\n",
        "# test_images = test_images.astype('float32') / 255\n",
        "\n",
        "# # Task 7: Define and train a simple neural network using Keras\n",
        "# # use Sequential model from keras.models\n",
        "# # use Dense layer from keras.layers\n",
        "# # use 'adam' as optimizer and 'categorical_crossentropy' as loss function\n",
        "# # use model.fit to train the model\n",
        "# model = keras.models.Sequential()\n",
        "# print('inp', train_images.shape[1])\n",
        "# input_shapes = [train_images.shape[1], 32, 32, 10]\n",
        "# model.add(keras.layers.Dense(input_shapes[1], input_shape=(input_shapes[0],), activation='softmax'))\n",
        "# model.add(keras.layers.Dense(input_shapes[2], input_shape=(input_shapes[1],), activation='softmax'))\n",
        "# model.add(keras.layers.Dense(input_shapes[3], input_shape=(input_shapes[2],), activation='relu'))\n",
        "# opt = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "# model.compile(\n",
        "#     optimizer = opt,\n",
        "#     loss = 'categorical_crossentropy',\n",
        "#     metrics = ['accuracy']\n",
        "# )\n",
        "# print(model.summary())\n",
        "# model.fit(train_images, labels_train)\n",
        "\n",
        "# # Task 8: Evaluate the neural network on the testing data\n",
        "# # use model.evaluate to get the test loss and test accuracy\n",
        "# scores = model.evaluate(test_images, labels_test)\n",
        "# print(\"Accuracy: %d%%\" % (scores[1]*100))\n",
        "\n",
        "# Task 9: Define a simple linear regression model using PyTorch\n",
        "# create a class LinearRegression that inherit from nn.Module\n",
        "# define the constructor and forward function\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        # self.activation = nn.ReLU()\n",
        "        return x\n",
        "\n",
        "# Task 10: Train the linear regression model on some dummy data and print the weight and bias\n",
        "# create an instance of LinearRegression\n",
        "# use nn.MSELoss as criterion, optim.SGD as optimizer\n",
        "# use model.parameters() as input for optimizer\n",
        "# use optimizer.step() and criterion to update the model weight and bias\n",
        "\n",
        "# random data\n",
        "def generate_data(size):\n",
        "    x = torch.Tensor([[random.randint(0, 1000)] for _ in range(size)])\n",
        "    return x\n",
        "\n",
        "def linear_equation(x):\n",
        "    return torch.add(torch.mul(x, 2), 3) # y = 2*x + 3\n",
        "\n",
        "epochs = 1000\n",
        "linear = LinearRegression(1, 1)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(linear.parameters(), lr=0.005)\n",
        "for epoch in range(epochs):\n",
        "    x_data = generate_data(random.randint(1000, 2000))\n",
        "    y_data = linear_equation(x_data)\n",
        "    pred_y = linear(x_data)\n",
        "    loss = criterion(pred_y, y_data)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # print('epoch {}, loss {}, datasize {}'.format(epoch, loss.item(), len(x_data)))\n",
        "\n",
        "x_test = generate_data(100)\n",
        "y_test = linear_equation(x_test)\n",
        "pred_y = linear(x_test)\n",
        "print(len(pred_y), pred_y[0:10])\n",
        "print(len(y_test), y_test[0:10])\n",
        "train_acc = torch.sum(pred_y == y_test)\n",
        "final_train_acc = train_acc / len(x_test)\n",
        "print(\"Final Train Accuracy\", train_acc, final_train_acc)\n",
        "\n",
        "#TODO I think its not working because the loss and optimizer update is not reflected back to the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goIaALYXVy1J"
      },
      "source": [
        "# Bonus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZYu5X7gV1L9"
      },
      "outputs": [],
      "source": [
        "# Bonus Task: Implement a Convolutional Neural Network to classify the CIFAR-10 dataset\n",
        "# use torchvision.datasets.CIFAR10 to load the dataset\n",
        "# create a class CNN that inherit from nn.Module\n",
        "# define the constructor, forward function and the network architecture \n",
        "# use CrossEntropyLoss as criterion, optim.SGD as optimizer\n",
        "# use model.parameters() as input for optimizer\n",
        "# use optimizer.step() and criterion to update the model weight and bias"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "GIX",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "72c89bfd059e2267712ada51c88c396e1070a0d0c685545f7a398da337d403d6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
